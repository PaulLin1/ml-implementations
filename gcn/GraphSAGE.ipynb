{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torch_geometric"
      ],
      "metadata": {
        "id": "vG4LgT47_n8F",
        "outputId": "4cdf94ba-e480-4830-d0ab-128117ede7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vG4LgT47_n8F",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2275cd5-bceb-4579-8140-369991bd42a5",
      "metadata": {
        "id": "b2275cd5-bceb-4579-8140-369991bd42a5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import CoraFull\n",
        "from torch_geometric.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_5CuHAMpK1p"
      },
      "id": "Z_5CuHAMpK1p"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b2221090-4aca-49b3-a16b-ff9d85aec18e",
      "metadata": {
        "id": "b2221090-4aca-49b3-a16b-ff9d85aec18e",
        "outputId": "e96fa726-a1a5-473c-8ef7-021942f3ac29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from torch_geometric.data import DataLoader, NeighborSampler\n",
        "from torch_geometric.data import ClusterLoader\n",
        "dataset = CoraFull(root=\"cora\")\n",
        "data = dataset[0]\n",
        "# loader = ClusterLoader(dataset, batch_size=32, shuffle=True)\n",
        "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "data.y[0]\n",
        "# for batch in loader:\n",
        "#   print(len(batch.x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.y[0]  # Single label\n",
        "print(y)\n",
        "y = y.unsqueeze(0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "T560-Z9eYOya",
        "outputId": "cc75d7d4-e012-42db-fd1f-3b50cdd61843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T560-Z9eYOya",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n",
            "tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0d38a6ff-5b1f-408b-a8e1-cf61a78bcf3a",
      "metadata": {
        "id": "0d38a6ff-5b1f-408b-a8e1-cf61a78bcf3a"
      },
      "outputs": [],
      "source": [
        "class MeanAggregator(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features, neigh_input_dim):\n",
        "        super(MeanAggregator, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.neigh_input_dim = neigh_input_dim\n",
        "\n",
        "        self.w = torch.nn.Parameter(torch.empty(neigh_input_dim + in_features, out_features))\n",
        "        torch.nn.init.xavier_uniform_(self.w)\n",
        "\n",
        "    def forward(self, x, sampled_neighbors):\n",
        "        neighbors_message = torch.mean(sampled_neighbors, dim=0)\n",
        "        message = torch.concat((x, neighbors_message), 0)\n",
        "        weighted_message = torch.matmul(message, self.w)\n",
        "        return weighted_message"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GraphSAGE, self).__init__()\n",
        "    self.aggr1 = MeanAggregator(8710, 5000, 8710)\n",
        "    self.aggr2 = MeanAggregator(5000, 1000, 8710)\n",
        "    self.aggr3 = MeanAggregator(1000, 70, 8710)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x, neighbors = input\n",
        "    h = torch.nn.functional.relu(self.aggr1(x, neighbors))\n",
        "    h = torch.nn.functional.relu(self.aggr2(h, neighbors))\n",
        "    logits = self.aggr3(h, neighbors)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "BloP67VxhNxJ"
      },
      "id": "BloP67VxhNxJ",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE()\n",
        "x = data.x[0]\n",
        "mask = data.edge_index[0] == 0\n",
        "node_neighbors = torch.stack([data.x[i] for i in data.edge_index[1][mask]])\n",
        "\n",
        "y = data.y[0]\n",
        "model((x, node_neighbors))\n",
        "# print(model.aggr2.w)"
      ],
      "metadata": {
        "id": "_byIAWSSOdTo",
        "outputId": "92e47ca1-7f5f-4b11-bdba-7706cd3e4f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_byIAWSSOdTo",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0230,  0.0044, -0.0341,  0.0342,  0.0241, -0.0357, -0.1257, -0.0075,\n",
              "        -0.0434, -0.0055, -0.0643,  0.0931, -0.0191,  0.0005,  0.0395, -0.0182,\n",
              "        -0.0125,  0.0066, -0.0518, -0.0556,  0.0033, -0.0376, -0.0341,  0.0505,\n",
              "         0.0579,  0.0084,  0.1447,  0.0144, -0.0540,  0.1284, -0.0007,  0.0128,\n",
              "         0.0483, -0.0189, -0.0183,  0.0078,  0.0433,  0.0852, -0.0896, -0.0015,\n",
              "         0.0092,  0.0155,  0.0103,  0.0422,  0.0793, -0.0095,  0.0934,  0.1117,\n",
              "        -0.0490, -0.0435, -0.1044, -0.0177, -0.0536,  0.0043,  0.0141,  0.0512,\n",
              "         0.0259, -0.0688,  0.0282, -0.0557, -0.0899,  0.0236,  0.0986,  0.0154,\n",
              "        -0.0231, -0.0244,  0.0287, -0.0281, -0.0715, -0.0588],\n",
              "       grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE()\n",
        "loss_fn= torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(100):\n",
        "  for i in range(len(data.x[0])):\n",
        "    optimizer.zero_grad()\n",
        "    x = data.x[i]\n",
        "    mask = data.edge_index[0] == i\n",
        "    node_neighbors = torch.stack([data.x[i] for i in data.edge_index[1][mask]])\n",
        "\n",
        "    # node_neighbors = torch.stack([data.x[v] for u, v in zip(data.edge_index[0], data.edge_index[1]) if data.edge_index[0][u] == i])\n",
        "    y = data.y[i]\n",
        "    y = y.unsqueeze(0)\n",
        "    pred = model((x, node_neighbors))\n",
        "    pred = pred.unsqueeze(0)\n",
        "    loss = loss_fn(pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "z-rD-Y4oBmaX",
        "outputId": "c81d7b29-abf7-4835-a2d3-173ff5a47d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "z-rD-Y4oBmaX",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.2482, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2538, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.0695, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1361, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7441, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.5899, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9139, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7674, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7593, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.7307, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.3861, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4778, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.2726, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.1753, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0753, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.0203, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.8119, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5446, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.4031, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.1439, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2511, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6352, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8180, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8526, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4151, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.6212, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6770, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6305, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6294, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1920, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6510, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5950, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8132, grad_fn=<NllLossBackward0>)\n",
            "tensor(5.4691, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3272, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2493, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1266, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1074, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1267, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1685, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.8494, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0297, grad_fn=<NllLossBackward0>)\n",
            "tensor(5.9620, grad_fn=<NllLossBackward0>)\n",
            "tensor(9.4528, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0622, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1817, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3446, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0971, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1613, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1161, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0630, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, grad_fn=<NllLossBackward0>)\n",
            "tensor(5.3990, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1080, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0386, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.9822, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0411, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1030, grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3904, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1778, grad_fn=<NllLossBackward0>)\n",
            "tensor(6.9741, grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5097, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1653, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1372, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1329, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4190, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3641, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1728, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2920, grad_fn=<NllLossBackward0>)\n",
            "tensor(6.3469, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0824, grad_fn=<NllLossBackward0>)\n",
            "tensor(7.5687, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0923, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3249, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2677, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4897, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1708, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1459, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0962, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3463, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3884, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, grad_fn=<NllLossBackward0>)\n",
            "tensor(5.0950, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0848, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1215, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-159c582422cc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOgfIDpzOPGW"
      },
      "id": "OOgfIDpzOPGW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}